{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformer_lens\n",
    "%pip install wandb\n",
    "\n",
    "def in_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "IN_COLAB = in_colab()\n",
    "\n",
    "if IN_COLAB:\n",
    "    # download files from the github repository\n",
    "    for file in ['model.py', 'replay.py', 'trainer.py', 'utils.py']:\n",
    "      !wget https://raw.githubusercontent.com/jacksonkunde/rlhf/main/{file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import RLHFTrainer\n",
    "from utils import RLHFTrainingArgs\n",
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import wandb\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens import utils, HookedTransformer\n",
    "from typing import List, Optional, Tuple, Union, Dict, Any, Callable\n",
    "import einops\n",
    "from jaxtyping import Float, Int\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_fn_char_count(generated_sample: Union[str, List[str]], char: str = '.') -> Union[float, Float[Tensor, \"batch\"]]:\n",
    "    '''\n",
    "    Reward function, evaluated on the generated samples.\n",
    "\n",
    "    In this case it's very simple: it just counts the number of instances of a particular character in\n",
    "    the generated sample. It returns a tensor of rewards of dtype float the input is a list, or a single\n",
    "    reward (float) if the input is a string.\n",
    "    '''\n",
    "    if isinstance(generated_sample, list):\n",
    "        return t.tensor([reward_fn_char_count(item) for item in generated_sample]).float().to(\"cuda\")\n",
    "    else:\n",
    "        return float(generated_sample.count(char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = RLHFTrainingArgs(use_wandb=False, reward_fn=reward_fn_char_count)\n",
    "trainer = RLHFTrainer(args)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
